{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor\n",
    "import patsy\n",
    "import statsmodels.api as sm\n",
    "from scipy.stats import ttest_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trips = pd.read_csv('FY2014 Ridership_Trolley_Sept2013Booking.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 1.) remove unnecessary columns: all we need is pole_id, time_start and meter_expire\n",
    "trips = trips[['STOP_ID', 'PASSENGERS_OFF', 'TIME_ACTUAL_ARRIVE']]\n",
    "trips.columns = ['stop_id', 'count', 'time']\n",
    "trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# clean the data, removing any na rows \n",
    "# we will also remove all rows that have value 0\n",
    "trips.dropna(how='any')\n",
    "trips = trips[trips['count'] != 0]\n",
    "trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.) using stop_id we can connect with lat/long. We will be grouping by pole_id to create\n",
    "#     a table with the following columns:\n",
    "#     (stop_id, latitude, longitude, count_am_early, count_am_peak, \n",
    "#        count_midday, count_pm_early, count_pm_late, count_daily)\n",
    "# NOTE: we will need to decide whether to use raw numbers or averages of counts per section per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_locs = pd.read_csv('FY2014 Ridership_Trolley_Sept2013_Stops.csv')\n",
    "stop_locs = stop_locs[['STOP_ID', 'LAT', 'LON']]\n",
    "stop_locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop_locs.columns = ['stop_id', 'latitude', 'longitude']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stops_df = trips.merge(stop_locs, how='left')\n",
    "stops_df = stops_df.dropna(how='any')\n",
    "stops_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_counts = stops_df.groupby(['stop_id']).agg('count')\n",
    "stop_counts = stop_counts['time'] #remove unnecessary columns\n",
    "stop_counts = stop_counts.to_frame()\n",
    "stop_counts['stop_id'] = stop_counts.index\n",
    "stop_counts = stop_counts.merge(stop_locs, how='left')\n",
    "stop_counts.columns = ['total_count', 'stop_id', 'latitude', 'longitude']\n",
    "stop_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# we need to now find the number of days in the transactions dataset\n",
    "# we will be using this in order to get the count of transactions PER DAY\n",
    "stops_df['time'] = pd.to_datetime(stops_df['time'])\n",
    "dates = stops_df['time']\n",
    "am_early_d = {}\n",
    "am_peak_d = {}\n",
    "midday_d = {}\n",
    "pm_peak_d = {}\n",
    "pm_late_d = {}\n",
    "\n",
    "def classify(x): \n",
    "    hour = x.time().hour\n",
    "    if hour <=6:\n",
    "        return 'am_early'\n",
    "    elif hour <=9:\n",
    "        return 'am_peak'\n",
    "    elif hour <=14:\n",
    "        return 'midday'\n",
    "    elif hour <=19:\n",
    "        return 'pm_peak'\n",
    "    else:\n",
    "        return 'pm_late'\n",
    "stops_df['time_slot'] = stops_df['time'].apply(classify)\n",
    "stops_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def checkSeriesColumn(s, col):\n",
    "    val = False\n",
    "    for row in s.keys().to_series().str.contains(col): \n",
    "        if(row == True):\n",
    "            val = True\n",
    "    return val\n",
    "def set_temporal_counts(p_id):\n",
    "    v_counts = stops_df.loc[stops_df['stop_id'] == p_id]['time_slot'].value_counts(dropna=False)\n",
    "    stop_counts.loc[stop_counts['stop_id'] == p_id,'am_early'] = 0 if not checkSeriesColumn(v_counts, 'am_early') else v_counts['am_early']\n",
    "    stop_counts.loc[stop_counts['stop_id'] == p_id,'am_peak'] =  0 if not checkSeriesColumn(v_counts, 'am_peak') else v_counts['am_peak']\n",
    "    stop_counts.loc[stop_counts['stop_id'] == p_id,'midday'] =  0 if not checkSeriesColumn(v_counts, 'midday') else v_counts['midday']\n",
    "    stop_counts.loc[stop_counts['stop_id'] == p_id,'pm_peak'] =  0 if not checkSeriesColumn(v_counts, 'pm_peak') else v_counts['pm_peak']\n",
    "    stop_counts.loc[stop_counts['stop_id'] == p_id,'pm_late'] = 0 if not checkSeriesColumn(v_counts, 'pm_late') else v_counts['pm_late']\n",
    "#     park_counts.loc[park_counts['pole_id'] == ]\n",
    "# #      park_counts.loc[park_counts['pole_id'] == p_id,'am_early'] = 0 if not checkSeriesColumn(v_counts, 'am_early') else v_counts['am_early']\n",
    "# #      park_counts.loc[park_counts['pole_id'] == p_id,'am_peak'] =  0 if not checkSeriesColumn(v_counts, 'am_peak') else v_counts['am_peak']\n",
    "# #     park_counts.loc[park_counts['pole_id'] == p_id,'midday'] =  0 if not checkSeriesColumn(v_counts, 'midday') else v_counts['midday']\n",
    "# #     park_counts.loc[park_counts['pole_id'] == p_id,'pm_peak'] =  0 if not checkSeriesColumn(v_counts, 'pm_peak') else v_counts['pm_peak']\n",
    "# #     park_counts.loc[park_counts['pole_id'] == p_id,'pm_late'] = 0 if not checkSeriesColumn(v_counts, 'pm_late') else v_counts['pm_late']\n",
    "\n",
    "# v_counts = stops_df[stops_df['stop_id'] == 75060]['time_slot'].value_counts(dropna=False).plot(kind='bar')\n",
    "# f3 = plt.gcf()\n",
    "stop_counts['stop_id'].apply(set_temporal_counts)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# v_counts = park_df.loc[park_df['pole_id'] == 'N-1003']['time_slot'].value_counts(dropna=False)\n",
    "# park_counts.loc[park_counts['pole_id'] == 'N-1003','am_early'] = 0 if not checkSeriesColumn(v_counts, 'am_early') else v_counts['am_early']\n",
    "# park_counts.loc[park_counts['pole_id'] == 'N-1003','am_peak'] =  0 if not checkSeriesColumn(v_counts, 'am_peak') else v_counts['am_peak']\n",
    "# park_counts.loc[park_counts['pole_id'] == 'N-1003','midday'] =  0 if not checkSeriesColumn(v_counts, 'midday') else v_counts['midday']\n",
    "# park_counts.loc[park_counts['pole_id'] == 'N-1003','pm_peak'] =  0 if not checkSeriesColumn(v_counts, 'pm_peak') else v_counts['pm_peak']\n",
    "# park_counts.loc[park_counts['pole_id'] == 'N-1003','pm_late'] = 0 if not checkSeriesColumn(v_counts, 'pm_late') else v_counts['pm_late']\n",
    "# park_counts.loc[park_counts['pole_id'] == 'N-1003']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stop_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# stop_counts.to_csv(\"Stop_Counts.csv\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "####Rough Calculations for algorithm\n",
    "long_max = stop_counts['longitude'].max()\n",
    "long_min = stop_counts['longitude'].min()\n",
    "lat_max = stop_counts['latitude'].max()\n",
    "lat_min = stop_counts['latitude'].min()\n",
    "lat_dif = lat_max - lat_min\n",
    "long_dif = long_max - long_min\n",
    "NUMBER_BLOCKS_ROOT = 10 #this means 100 blocks 10x10\n",
    "lat_gap = lat_dif / NUMBER_BLOCKS_ROOT\n",
    "long_gap = long_dif / NUMBER_BLOCKS_ROOT\n",
    "\n",
    "def classify_blocks(s):\n",
    "    stop_counts.loc[stop_counts['stop_id'] == s,'row'] =  (stop_counts.loc[stop_counts['stop_id'] == s,'latitude'] - lat_min) // lat_gap\n",
    "    stop_counts.loc[stop_counts['stop_id'] == s,'col'] = (stop_counts.loc[stop_counts['stop_id'] == s,'longitude'] - long_min) // long_gap\n",
    "\n",
    "stop_counts['stop_id'].apply(classify_blocks)\n",
    "\n",
    "stop_counts\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
